{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3e8e16",
   "metadata": {},
   "source": [
    "# Custom Object and Scene detection using Amazon Rekognition Custom Labels API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67d210",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook provides a walkthrough of [Amazon Rekognition Custom Labels API](https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/custom-labels-api-reference.html) to identify custom objects and scenes.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecbb8bd",
   "metadata": {},
   "source": [
    "***\n",
    "<b>Setup</b>\n",
    "1. Amazon SageMaker Notebook is not a requirement to use Amazon Rekognition APIs. For this notebook, it provides an environment to run python code and make API calls.\n",
    "2. Create an [Amazon SageMaker Notebook instance](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html)\n",
    "3. Click the Amazon SageMaker Notebook instance and open the Role.\n",
    "4. For this demonstration in the Permissions tab, choose Attach policies. Add the AmazonRekognitionCustomLabelsFullAccess, AmazonSageMakerFullAccess and AmazonS3FullAccess. This provides full access to Amazon Sagemaker,Amazon Rekognition Custom labels and Amazon S3 service but we would recommend to trim down the access policies for a production application.\n",
    "5. Return to the Amazon Sagemaker Notebook insatnce, Under Actions, click on “Open JupyterLab”\n",
    "6. Open the terminal\n",
    "7. Run cd SageMaker/\n",
    "8. Run git clone https://github.com/aws-samples/amazon-rekognition-code-samples.git\n",
    "9. Open the “custom-labels” folder within “amazon-rekognition-code-samples” created under “Files” tab.\n",
    "10. You should see two jupyter notebooks. You can continue with the rest of the notebook.\n",
    "11. If you receive Kernel not found, select “conda_python3” from the dropdown on Top right.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Upgrade boto3 and botocore\n",
    "# !pip install botocore --upgrade\n",
    "# !pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b68bcaa",
   "metadata": {},
   "source": [
    "### Initialize Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727cd21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "\n",
    "import boto3\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import time\n",
    "import os\n",
    "\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319c95e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Curent AWS Region. Use this to choose corresponding S3 bucket with sample content\n",
    "\n",
    "mySession = boto3.session.Session()\n",
    "awsRegion = mySession.region_name\n",
    "print (\"AWS Region : \" + awsRegion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9489fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Init clients\n",
    "rekognition = boto3.client('rekognition')\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b32c1",
   "metadata": {},
   "source": [
    "***\n",
    "Activities\n",
    "***\n",
    "In this notebook, we will Train an Amazon Rekognition Custom Label model to detect different Dog breeds.\n",
    "1. Initialize Amazon Rekognition Custom Labels.\n",
    "2. Download the Public Stanford Dog Datasets.\n",
    "3. Prepare the datasets and generating manifest file.\n",
    "4. Create an Amazon Rekognition Custom Label Project.\n",
    "5. Import the Datasets into the new Amazon Rekognition Custom Label Project.\n",
    "6. Split the dataset into Training and Test using Rekognition Custom Label API.\n",
    "7. Train a Custom Model to detect Dog breed.\n",
    "8. Retrieve the Model Metrics.\n",
    "9. Start the Inference endpoint.\n",
    "10. Run predictions on the holdout dataset.\n",
    "11. Stop the Inference endpoint.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf12a0",
   "metadata": {},
   "source": [
    "### Initialize Amazon Rekognition Custom Labels\n",
    "\n",
    "- 아래에 bucket 명은 AWS console에서 Rekognition custom label 들어가서 만든 기본 bucket 이름을 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb83e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Please replace the <rek_cl_default_bucket_name> with the value of the Amazon S3 bucket name captured above. It will be different in your case.\n",
    "rek_cl_default_bucket = \"<rek_cl_default_bucket_name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88b0db",
   "metadata": {},
   "source": [
    "### Download the Public Stanford Dog Datasets\n",
    "***\n",
    "1. Download the images in the dataset from Stanford University.\n",
    "2. Download the annotation of the images in the dataset from Stanford University.\n",
    "3. Prepare the datsets and image annotation using the manifest file.\n",
    "4. Copy the dataset to Rekognition Custom Label's default bucket.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b2f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Download the images in the dataset from Stanford University found here - http://vision.stanford.edu/aditya86/ImageNetDogs/.\n",
    "## Please note you comply with all license requirements before downloading the datasets.\n",
    "## You may manually download the dataset and place it in the respective directories in the your current directory.\n",
    "## The below sample code snippet provides guidance around the steps for downloading the dataset .\n",
    "\n",
    "## Dataset and Annotation dataset url\n",
    "stanford_dog_dataset_image_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
    "stanford_dog_dataset_annotation_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar\"\n",
    "\n",
    "## Creating directories in the current location\n",
    "!mkdir -p ./stanford_dog_dataset/images_tar\n",
    "!mkdir -p ./stanford_dog_dataset/images\n",
    "!mkdir -p ./stanford_dog_dataset/annotation_tar\n",
    "!mkdir -p ./stanford_dog_dataset/annotation\n",
    "\n",
    "## Download the dataset to the directories created above\n",
    "!curl $stanford_dog_dataset_image_url --output ./stanford_dog_dataset/images_tar/images.tar\n",
    "!curl $stanford_dog_dataset_annotation_url --output ./stanford_dog_dataset/annotation_tar/annotation.tar\n",
    "\n",
    "\n",
    "## Unzipping the downlaoded datasets.\n",
    "!tar -xf ./stanford_dog_dataset/images_tar/images.tar -C ./stanford_dog_dataset/images --no-same-owner\n",
    "!tar -xf ./stanford_dog_dataset/annotation_tar/annotation.tar -C ./stanford_dog_dataset/annotation --no-same-owner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f84df",
   "metadata": {},
   "source": [
    "### Prepare the datasets and generating manifest file\n",
    "***\n",
    "The original dataset contains 120 classes and 20,000+ images. \n",
    "<br>This is possible to train with custom labels, but it will take many hours. \n",
    "<br>In order to reduce the training time we will trim the classes to 3 and give them easier to read names. \n",
    "<br>We will also demonstrate the generation of a Amazon Sageamker Groundtruth manifest file from the XML format annotation available with the public dataset. \n",
    "<br>We will also select 1 image from each class along with an image from unknown class and keep it aside as a holdout dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb0e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function to convert a list of stanford dog dataset annotation to generate a single Amazon Sagemaker groundtruth manifest file.\n",
    "def generate_manifest_file (stanford_dog_dataset_annotation, final_manifest_file_path):\n",
    "    final_file=[]\n",
    "    class_dict={}\n",
    "    for filename in stanford_dog_dataset_annotation:\n",
    "        file_pth = filename.replace('/images/Images/','/annotation/Annotation/').replace('.jpg','')\n",
    "        # print(file_pth)\n",
    "        file = open(file_pth, mode = 'r' )\n",
    "        annt = file.read()\n",
    "        # print (annt)\n",
    "        singl_file = {}\n",
    "        # print (\"\\n\")\n",
    "        root = ET.fromstring(annt)\n",
    "        img_size = {}\n",
    "        img_nm = None\n",
    "        for child in root:\n",
    "            if (child.tag == 'filename'):\n",
    "                # print (child.text)\n",
    "                img_nm = child.text\n",
    "\n",
    "            if (child.tag == 'size'):\n",
    "                for elem in child.iter():\n",
    "                    if (elem.tag == 'width'):\n",
    "                        # print (elem.text)\n",
    "                        img_size[\"width\"]=int(elem.text)\n",
    "                    if (elem.tag == 'height'):\n",
    "                        # print (elem.text)\n",
    "                        img_size[\"height\"] = int(elem.text)\n",
    "                    if (elem.tag == 'depth'):\n",
    "                        # print (elem.text)\n",
    "                        img_size[\"depth\"] = int(elem.text)\n",
    "        # print (json.dumps(singl_file))\n",
    "        annotations = []\n",
    "        objects = []\n",
    "        class_map = {}\n",
    "        objcts = root.findall('object')\n",
    "        # print (len(objcts))\n",
    "        for objct in objcts:\n",
    "            annotation = {}\n",
    "            confidence = {}\n",
    "            class_nm = None\n",
    "            class_id = None\n",
    "            for elem in objct.iter():\n",
    "                if (elem.tag == 'name'):\n",
    "                    # print(elem.text)\n",
    "                    class_nm = elem.text\n",
    "                    class_id = class_dict.get(class_nm, None)\n",
    "                    if class_id == None:\n",
    "                        if len(class_dict) == 0:\n",
    "                            class_id = 0\n",
    "                        else:\n",
    "                            all_values = class_dict.values()\n",
    "                            max_value = max(all_values)\n",
    "                            class_id = int(max_value) + 1\n",
    "                        class_dict[class_nm] = class_id\n",
    "\n",
    "                if (elem.tag == 'bndbox'):\n",
    "                    xmin = ymin = xmax = ymax = 0\n",
    "                    for subelem in elem.iter():\n",
    "                        if (subelem.tag == 'xmin'):\n",
    "                            # print(subelem.text)\n",
    "                            xmin = int(subelem.text)\n",
    "                        if (subelem.tag == 'ymin'):\n",
    "                            # print(subelem.text)\n",
    "                            ymin = int(subelem.text)\n",
    "                        if (subelem.tag == 'xmax'):\n",
    "                            # print(subelem.text)\n",
    "                            xmax = int(subelem.text)\n",
    "                        if (subelem.tag == 'ymax'):\n",
    "                            # print(subelem.text)\n",
    "                            ymax = int(subelem.text)\n",
    "\n",
    "                    annotation[\"class_id\"] = class_id\n",
    "                    annotation[\"top\"] = ymin\n",
    "                    annotation[\"left\"] = xmin\n",
    "                    annotation[\"width\"] = xmax - xmin\n",
    "                    annotation[\"height\"] = ymax - ymin\n",
    "                    annotations.append(annotation)\n",
    "\n",
    "                    confidence[\"confidence\"] = 1\n",
    "                    objects.append(confidence)\n",
    "\n",
    "                    class_map[class_id] = class_nm\n",
    "        bbx = {\n",
    "            \"image_size\" : [img_size],\n",
    "            \"annotations\" : annotations\n",
    "        }\n",
    "\n",
    "        bbx_mtdata = {\n",
    "            \"objects\" : objects,\n",
    "            \"class-map\" : class_map,\n",
    "            \"type\": \"groundtruth/object-detection\",\n",
    "            \"human-annotated\": \"yes\",\n",
    "            \"creation-date\": datetime.today().strftime('%Y-%m-%dT%H:%m:%S'), \n",
    "            \"job-name\": \"testjob\"\n",
    "        }\n",
    "\n",
    "\n",
    "        singl_file = {\n",
    "            \"source-ref\" : f's3://{rek_cl_default_bucket}/stanford_dog_dataset/dataset/{img_nm}.jpg',\n",
    "            \"bounding-box\" : bbx,\n",
    "            \"bounding-box-metadata\" : bbx_mtdata\n",
    "\n",
    "        }\n",
    "\n",
    "        # print (json.dumps(singl_file))\n",
    "        imglbl = json.dumps(singl_file)\n",
    "        final_file.append(imglbl + \" \\n\")\n",
    "        file.close()\n",
    "    \n",
    "    file1 = open(final_manifest_file_path, \"w\")\n",
    "    file1.writelines(final_file)\n",
    "    file1.close()\n",
    "    \n",
    "    print(f\"Local manifest path : {final_manifest_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d8150-b279-4006-bdc2-9acbd783afc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05820f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_to_be_trained = [\n",
    "    \"n02090379-redbone\", \n",
    "    \"n02099601-golden_retriever\", \n",
    "    \"n02107142-Doberman\" \n",
    "]\n",
    "\n",
    "holdoutset_list = {\n",
    "    \"n02090379-redbone\" : \"./stanford_dog_dataset/images/Images/n02090379-redbone/n02090379_1799.jpg\",\n",
    "    \"n02099601-golden_retriever\" : \"./stanford_dog_dataset/images/Images/n02099601-golden_retriever/n02099601_3388.jpg\",\n",
    "    \"n02107142-Doberman\" : \"./stanford_dog_dataset/images/Images/n02107142-Doberman/n02107142_385.jpg\",\n",
    "    ## the below image is from a new class which is not included as part of the training set\n",
    "    \"n02091831-Saluki\" : \"./stanford_dog_dataset/images/Images/n02091831-Saluki/n02091831_3909.jpg\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee67797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "\n",
    "## Generating trim dataset\n",
    "makedirs(\"./stanford_dog_dataset/holdout\", exist_ok=True)\n",
    "for class_nm in classes_to_be_trained:\n",
    "    new_path = f'./stanford_dog_dataset/dataset/'\n",
    "    makedirs(new_path, exist_ok=True)\n",
    "    \n",
    "    existing_path = f'./stanford_dog_dataset/images/Images/{class_nm}'\n",
    "    onlyfiles = [join(existing_path, f) for f in listdir(existing_path) if isfile(join(existing_path, f))]\n",
    "    # remove the image from the list which is kept as part of the holdout dataset.\n",
    "    onlyfiles.remove(holdoutset_list[class_nm])\n",
    "    \n",
    "    for dataset_file_pth in onlyfiles:\n",
    "        dataset_list.append(dataset_file_pth)\n",
    "        dest_dataset_image_path = f'{new_path}/{dataset_file_pth.split(\"/\")[-1]}'\n",
    "        shutil.copy(dataset_file_pth, dest_dataset_image_path)\n",
    "\n",
    "## Generating dataset manifest file\n",
    "generate_manifest_file (dataset_list, './stanford_dog_dataset/dataset/dataset.manifest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9c0eab-fa5b-48f2-ad34-52b5d835e7b1",
   "metadata": {},
   "source": [
    "### Custom label을 위한 정답 포맷\n",
    "- 위의 과정은 custom dataset의 정답을 Amazon rekognition에서 활용할 수 있는 형태로 변경하는 과정입니다. 아래와 같은 포맷을 가지게 됩니다.\n",
    "\n",
    "```\n",
    "{\n",
    "   \"source-ref\":\"s3://custom-labels-console-ap-northeast-2-feed27152b/stanford_dog_dataset/dataset/n02090379_4611.jpg\",\n",
    "   \"bounding-box\":{\n",
    "      \"image_size\":[\n",
    "         {\n",
    "            \"width\":500,\n",
    "            \"height\":338,\n",
    "            \"depth\":3\n",
    "         }\n",
    "      ],\n",
    "      \"annotations\":[\n",
    "         {\n",
    "            \"class_id\":0,\n",
    "            \"top\":11,\n",
    "            \"left\":90,\n",
    "            \"width\":261,\n",
    "            \"height\":326\n",
    "         }\n",
    "      ]\n",
    "   },\n",
    "   \"bounding-box-metadata\":{\n",
    "      \"objects\":[\n",
    "         {\n",
    "            \"confidence\":1\n",
    "         }\n",
    "      ],\n",
    "      \"class-map\":{\n",
    "         \"0\":\"redbone\"\n",
    "      },\n",
    "      \"type\":\"groundtruth/object-detection\",\n",
    "      \"human-annotated\":\"yes\",\n",
    "      \"creation-date\":\"2023-05-15T07:05:22\",\n",
    "      \"job-name\":\"testjob\"\n",
    "   }\n",
    "}\n",
    "```\n",
    "\n",
    "- AWS 문서 참고: https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/md-dataset-purpose.html#md-dataset-purpose-localization\n",
    "- 예시 참고: https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/md-localize-objects.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce87783-2b1f-4818-90e9-337161e145bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## Copying the holdout dataset images\n",
    "for class_nm, file_path in holdoutset_list.items():\n",
    "    dest_holdout_image_path = f'./stanford_dog_dataset/holdout/{class_nm.split(\"-\")[-1]}.jpg'\n",
    "    shutil.copy(file_path, dest_holdout_image_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "## Copy the datasets and holdout set to the Amazon Rekognition Custom Label default S3 bucket\n",
    "!aws s3 cp ./stanford_dog_dataset/dataset/ s3://$rek_cl_default_bucket/stanford_dog_dataset/dataset/ --recursive --quiet\n",
    "!aws s3 cp ./stanford_dog_dataset/holdout/ s3://$rek_cl_default_bucket/stanford_dog_dataset/holdout/ --recursive --quiet\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8536c659",
   "metadata": {},
   "source": [
    "### Create an Amazon Rekognition Custom Label Project\n",
    "***\n",
    "Create an Amazon Rekognition Custom Label Project using the APIs\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb43d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cl_project = rekognition.create_project(\n",
    "    ProjectName='stanford_dogs_rek_custom'\n",
    ")\n",
    "JSON(cl_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc8be9",
   "metadata": {},
   "source": [
    "### Import the Datasets into the new Amazon Rekognition Custom Label Project\n",
    "***\n",
    "Import the Datasets into the new Amazon Rekognition Custom Label Project using the APIs.\n",
    "In this section we will import the entire dataset as training dataset and later we will demonstrate how we can use the Amazon Rekgniton out of the box to automatically keep aside 20% of the dataset as Test dataset.\n",
    "\n",
    "Training Dataset -> A set of labeled or annotated images which will be used to train the model. The model will be trained on this dataset.\n",
    "<br>\n",
    "Test Dataset -> A set of labeled or annotated images which will be used to evaluate the model.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d04ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## We will use the dataset.manifest file which was created earlier, to create a training dataset.\n",
    "cl_dataset_train = rekognition.create_dataset(\n",
    "                        DatasetSource={\n",
    "                            'GroundTruthManifest': {\n",
    "                                'S3Object': {\n",
    "                                    'Bucket': rek_cl_default_bucket,\n",
    "                                    'Name': 'stanford_dog_dataset/dataset/dataset.manifest'\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        DatasetType='TRAIN',\n",
    "                        ProjectArn=cl_project['ProjectArn']\n",
    "                    )\n",
    "JSON(cl_dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4e478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Wait for the creation of the train dataset to complete\n",
    "chk_status = True\n",
    "starttime = time.time()\n",
    "while (chk_status):\n",
    "    ## wait for 1 minute. To check status every 1 minutes\n",
    "    time.sleep (60)\n",
    "    dataset_status = rekognition.describe_dataset(\n",
    "                            DatasetArn=cl_dataset_train['DatasetArn']\n",
    "                        )\n",
    "    if ( (dataset_status['DatasetDescription']['Status'] != 'CREATE_IN_PROGRESS') ):\n",
    "        chk_status = False\n",
    "    ## Continue to check for status for 1 hour\n",
    "    if ((time.time() - starttime) > 3600):\n",
    "        chk_status = False\n",
    "        # Raise an exception if needed\n",
    "        \n",
    "JSON(dataset_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe38ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## We will a create an empty test dataset. As we will use the distribute dataset api later to keep aside 20% of training data for the training dataset\n",
    "cl_dataset_test = rekognition.create_dataset(\n",
    "                DatasetType='TEST',\n",
    "                ProjectArn=cl_project['ProjectArn']\n",
    "            )\n",
    "JSON(cl_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc71d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Wait for the creation of the empty test dataset to complete\n",
    "chk_status = True\n",
    "starttime = time.time()\n",
    "while (chk_status):\n",
    "    ## wait for 1 minute. To check status every 1 minutes\n",
    "    time.sleep (60)\n",
    "    dataset_status = rekognition.describe_dataset(\n",
    "                            DatasetArn=cl_dataset_test['DatasetArn']\n",
    "                        )\n",
    "    if ( (dataset_status['DatasetDescription']['Status'] != 'CREATE_IN_PROGRESS') ):\n",
    "        chk_status = False\n",
    "    ## Continue to check for status for 1 hour\n",
    "    if ((time.time() - starttime) > 3600):\n",
    "        chk_status = False\n",
    "        # Raise an exception if needed\n",
    "        \n",
    "JSON(dataset_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed62203a",
   "metadata": {},
   "source": [
    "### Split the dataset into Training and Test datasets using Rekognition Custom Label API\n",
    "***\n",
    "Here we will use the [distribute_dataset_entries](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.distribute_dataset_entries) API to automatically generate a Test dataset which will be used to evaluate the model.\n",
    "<br>The activity of splitting the dataset needs to be done only once for each project. Later we can add images to the training or test dataset using the [update_dataset_entries](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.update_dataset_entries) api to update/extend the training and test datasets.\n",
    "<br>Another option would be to create a training and test dataset. Then use [create_dataset](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.create_dataset) api to create a training and test dataset for that project. </br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8f06a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Split the dataset that was created earlier into Training and Test dataset\n",
    "cl_distribute_dataset = rekognition.distribute_dataset_entries(\n",
    "                            Datasets=[\n",
    "                                {\n",
    "                                    'Arn': cl_dataset_train['DatasetArn']\n",
    "                                },\n",
    "                                {\n",
    "                                    'Arn': cl_dataset_test['DatasetArn']\n",
    "                                }\n",
    "                            ]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f985f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Wait for the splitting of the dataset to complete\n",
    "chk_status = True\n",
    "starttime = time.time()\n",
    "while (chk_status):\n",
    "    ## wait for 1 minute. To check status every 1 minutes\n",
    "    time.sleep (60)\n",
    "    dataset_status_train = rekognition.describe_dataset(\n",
    "                                DatasetArn=cl_dataset_train['DatasetArn']\n",
    "                            )\n",
    "    dataset_status_test = rekognition.describe_dataset(\n",
    "                                DatasetArn=cl_dataset_test['DatasetArn']\n",
    "                            )\n",
    "    if ( (dataset_status_train['DatasetDescription']['Status'] != 'CREATE_IN_PROGRESS') and (dataset_status_test['DatasetDescription']['Status'] != 'CREATE_IN_PROGRESS') ):\n",
    "        chk_status = False\n",
    "    ## Continue to check for status for 1 hour\n",
    "    if ((time.time() - starttime) > 3600):\n",
    "        chk_status = False\n",
    "        # Raise an exception if needed\n",
    "        \n",
    "JSON(dataset_status_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47e988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JSON(dataset_status_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97341909",
   "metadata": {},
   "source": [
    "Check datasets from the AWS Console if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6ff46",
   "metadata": {},
   "source": [
    "### Train a Custom Model to detect Dog breed\n",
    "***\n",
    "Here we will use the [create_project_version](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.create_project_version) API to train the model.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6a08e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Start Training the model\n",
    "model_version_name = f'model_v{str(int(time.time()))}'\n",
    "cl_train_model = rekognition.create_project_version(\n",
    "                        ProjectArn=cl_project['ProjectArn'],\n",
    "                        VersionName=model_version_name,\n",
    "                        OutputConfig={\n",
    "                            'S3Bucket': rek_cl_default_bucket,\n",
    "                            'S3KeyPrefix': 'stanford_dog_dataset/model_train'\n",
    "                        }\n",
    "                    )\n",
    "JSON(cl_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e2589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Wait for the training to finish. This may take 2 to 4 hours\n",
    "chk_status = True\n",
    "starttime = time.time()\n",
    "while (chk_status):\n",
    "    ## wait for 2 minute. To check status every 2 minutes\n",
    "    time.sleep (120)\n",
    "    model_traing_status = rekognition.describe_project_versions(\n",
    "                                ProjectArn=cl_project['ProjectArn'],\n",
    "                                VersionNames=[\n",
    "                                               model_version_name\n",
    "                                            ]\n",
    "        \n",
    "                            )\n",
    "    if ( (model_traing_status['ProjectVersionDescriptions'][0]['Status'] != 'TRAINING_IN_PROGRESS') ):\n",
    "        chk_status = False\n",
    "    ## Continue to check for status for 10 hour\n",
    "    if ((time.time() - starttime) > 36000):\n",
    "        chk_status = False\n",
    "        # Raise an exception if needed\n",
    "    print(\"Training ...\")\n",
    "        \n",
    "print(\"Finished. Check the status\")\n",
    "JSON(model_traing_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae44996",
   "metadata": {},
   "source": [
    "### Retrieve the Model Metrics\n",
    "***\n",
    "Here we will use the [describe_project_versions](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.describe_project_versions) API to retrive the trained model metrics.\n",
    "<br>To understand mroe about the metrics please refer [Metrics for evaluating your model](https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/im-metrics-use.html)\n",
    "<br> To programatically access more granular results related to the model. Please refer [Accessing Amazon Rekognition Custom Labels training results](https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/im-metrics-api.html)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00bef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics = rekognition.describe_project_versions(\n",
    "                                ProjectArn=cl_project['ProjectArn'],\n",
    "                                VersionNames=[\n",
    "                                               model_version_name\n",
    "                                            ]\n",
    "        \n",
    "                            )\n",
    "# model_metrics\n",
    "print (\"F1 Score \" + str(model_metrics['ProjectVersionDescriptions'][0]['EvaluationResult']['F1Score']))\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "content_object = s3.Object(model_metrics['ProjectVersionDescriptions'][0]['EvaluationResult']['Summary']['S3Object']['Bucket'], \n",
    "                          model_metrics['ProjectVersionDescriptions'][0]['EvaluationResult']['Summary']['S3Object']['Name'] )\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "\n",
    "JSON(json_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ab3ba-7239-48e1-90d2-48a808a06483",
   "metadata": {},
   "source": [
    "### 학습 지표 확인\n",
    "\n",
    "- 학습 완료된 내용은 AWS console에서도 동일하게 확인이 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affa376",
   "metadata": {},
   "source": [
    "### Start the trained model\n",
    "***\n",
    "Here we will use the [start_project_version](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.start_project_version) API to start the trained model.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a93cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_model = rekognition.start_project_version(\n",
    "                        ProjectVersionArn=model_metrics['ProjectVersionDescriptions'][0]['ProjectVersionArn'],\n",
    "                        MinInferenceUnits=1\n",
    "                    )\n",
    "JSON (start_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60add48b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Wait for the model to start\n",
    "chk_status = True\n",
    "starttime = time.time()\n",
    "while (chk_status):\n",
    "    ## wait for 1 minute. To check status every 1 minutes\n",
    "    time.sleep (60)\n",
    "    model_start_status = rekognition.describe_project_versions(\n",
    "                                ProjectArn=cl_project['ProjectArn'],\n",
    "                                VersionNames=[\n",
    "                                               model_version_name\n",
    "                                            ]\n",
    "        \n",
    "                            )\n",
    "    if ( (model_start_status['ProjectVersionDescriptions'][0]['Status'] != 'STARTING') ):\n",
    "        chk_status = False\n",
    "    ## Continue to check for status for 1 hour\n",
    "    if ((time.time() - starttime) > 3600):\n",
    "        chk_status = False\n",
    "        # Raise an exception if needed\n",
    "        \n",
    "JSON(model_start_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4480673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc82ebe",
   "metadata": {},
   "source": [
    "### Run tests on the holdout images\n",
    "***\n",
    "Here we will use the [detect_custom_labels](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.detect_custom_labels) API to retrieve the dog breeds. These images were kept aside and was not included into the training or test datasets.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2575a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Copyright 2021 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#PDX-License-Identifier: MIT-0 (For details, see https://github.com/awsdocs/amazon-rekognition-custom-labels-developer-guide/blob/master/LICENSE-SAMPLECODE.)\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "import logging\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def analyze_local_image(rek_client, model, photo, min_confidence):\n",
    "    \"\"\"\n",
    "    Analyzes an image stored as a local file.\n",
    "    :param rek_client: The Amazon Rekognition Boto3 client.\n",
    "    :param s3_connection: The Amazon S3 Boto3 S3 connection object.\n",
    "    :param model: The ARN of the Amazon Rekognition Custom Labels model that you want to use.\n",
    "    :param photo: The name and file path of the photo that you want to analyze.\n",
    "    :param min_confidence: The desired threshold/confidence for the call.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        logger.info (\"Analyzing local file: %s\", photo)\n",
    "        image=Image.open(photo) \n",
    "        image_type=Image.MIME[image.format]\n",
    "\n",
    "        if (image_type == \"image/jpeg\" or image_type== \"image/png\") == False:\n",
    "            logger.error(\"Invalid image type for %s\", photo)\n",
    "            raise ValueError(\n",
    "                f\"Invalid file format. Supply a jpeg or png format file: {photo}\"\n",
    "            )\n",
    "            \n",
    "        # get images bytes for call to detect_anomalies\n",
    "        image_bytes = io.BytesIO()\n",
    "        image.save(image_bytes, format=image.format)\n",
    "        image_bytes = image_bytes.getvalue()\n",
    "\n",
    "        response = rek_client.detect_custom_labels(Image={'Bytes': image_bytes},\n",
    "            MinConfidence=min_confidence,\n",
    "            ProjectVersionArn=model)\n",
    "\n",
    "        show_image (image, response)\n",
    "        return len(response['CustomLabels'])\n",
    "\n",
    "    except ClientError as err:\n",
    "        logger.error(format(err))\n",
    "        raise\n",
    "    \n",
    "\n",
    "def analyze_s3_image(rek_client,s3_connection, model,bucket,photo, min_confidence):\n",
    "    \"\"\"\n",
    "    Analyzes an image stored in the specified S3 bucket.\n",
    "    :param rek_client: The Amazon Rekognition Boto3 client.\n",
    "    :param s3_connection: The Amazon S3 Boto3 S3 connection object.\n",
    "    :param model: The ARN of the Amazon Rekognition Custom Labels model that you want to use.\n",
    "    :param bucket: The name of the S3 bucket that contains the image that you want to analyze.\n",
    "    :param photo: The name of the photo that you want to analyze.\n",
    "    :param min_confidence: The desired threshold/confidence for the call.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        #Get image from S3 bucket.\n",
    "        \n",
    "        logger.info(\"analyzing bucket: %s image: %s\", bucket, photo)\n",
    "        s3_object = s3_connection.Object(bucket,photo)\n",
    "        s3_response = s3_object.get()\n",
    "        \n",
    "\n",
    "        stream = io.BytesIO(s3_response['Body'].read())\n",
    "        image=Image.open(stream)\n",
    "\n",
    "        image_type=Image.MIME[image.format]\n",
    "\n",
    "        if (image_type == \"image/jpeg\" or image_type== \"image/png\") == False:\n",
    "            logger.error(\"Invalid image type for %s\", photo)\n",
    "            raise ValueError(\n",
    "                f\"Invalid file format. Supply a jpeg or png format file: {photo}\")\n",
    "                \n",
    "\n",
    "        img_width, img_height = image.size  \n",
    "        draw = ImageDraw.Draw(image)  \n",
    "        \n",
    "        #Call DetectCustomLabels \n",
    "        response = rek_client.detect_custom_labels(Image={'S3Object': {'Bucket': bucket, 'Name': photo}},\n",
    "            MinConfidence=min_confidence,\n",
    "            ProjectVersionArn=model)\n",
    "\n",
    "        show_image (image, response)\n",
    "        return len(response['CustomLabels'])\n",
    "\n",
    "    except ClientError as err:\n",
    "        logger.error(format(err))\n",
    "        raise\n",
    "\n",
    "def show_image(image, response):\n",
    "    \"\"\"\n",
    "    Displays the analyzed image and overlays analysis results\n",
    "    :param image: The analyzed image\n",
    "    :param response: the response from DetectCustomLabels\n",
    "    \"\"\"\n",
    "    try: \n",
    "        font_size=10\n",
    "        line_width=5\n",
    "\n",
    "        img_width, img_height = image.size  \n",
    "        draw = ImageDraw.Draw(image)  \n",
    "                \n",
    "        # calculate and display bounding boxes for each detected custom label       \n",
    "        image_level_label_height = 0\n",
    "        \n",
    "        for custom_label in response['CustomLabels']:\n",
    "            confidence=int(round(custom_label['Confidence'],0))\n",
    "            label_text=f\"{custom_label['Name']}:{confidence}%\"\n",
    "#             font = ImageFont.load(\"arial.pil\")\n",
    "            fnt = ImageFont.truetype(\"/usr/share/fonts/dejavu/DejaVuSans.ttf\", font_size)\n",
    "            text_width, text_height = draw.textsize(label_text,fnt)\n",
    "\n",
    "            logger.info(f\"Label: {custom_label['Name']}\") \n",
    "            logger.info(f\"Confidence:  {confidence}%\")\n",
    "\n",
    "            # Draw bounding boxes, if present\n",
    "            if 'Geometry' in custom_label:\n",
    "                box = custom_label['Geometry']['BoundingBox']\n",
    "                left = img_width * box['Left']\n",
    "                top = img_height * box['Top']\n",
    "                width = img_width * box['Width']\n",
    "                height = img_height * box['Height']\n",
    "                \n",
    "                logger.info(\"Bounding box\")\n",
    "                logger.info(\"\\tLeft: {0:.0f}\".format(left))\n",
    "                logger.info(\"\\tTop: {0:.0f}\".format(top))\n",
    "                logger.info(\"\\tLabel Width: {0:.0f}\".format(width))\n",
    "                logger.info(\"\\tLabel Height: {0:.0f}\".format(height))\n",
    "                \n",
    "                points = (\n",
    "                    (left,top),\n",
    "                    (left + width, top),\n",
    "                    (left + width, top + height),\n",
    "                    (left , top + height),\n",
    "                    (left, top))\n",
    "                #Draw bounding box and label text\n",
    "                draw.line(points, fill=\"limegreen\", width=line_width)\n",
    "                draw.rectangle([(left + line_width , top+line_width), (left + text_width + line_width, top + line_width + text_height)],fill=\"black\")\n",
    "                draw.text((left + line_width ,top +line_width), label_text, fill=\"limegreen\", font=fnt) \n",
    "            \n",
    "            #draw image-level label text.\n",
    "            else:\n",
    "                draw.rectangle([(10 , image_level_label_height), (text_width + 10, image_level_label_height+text_height)],fill=\"black\")\n",
    "                draw.text((10,image_level_label_height), label_text, fill=\"limegreen\", font=fnt)  \n",
    "\n",
    "                image_level_label_height += text_height\n",
    "            \n",
    "#         image.show()\n",
    "        display(image)\n",
    "\n",
    "    except Exception as err:\n",
    "        logger.error(format(err))\n",
    "        raise\n",
    "        \n",
    "\n",
    "def analyze_rekcl_bb(bckt_nm, pics, modelarn, minconfdnce):\n",
    "\n",
    "    try:\n",
    "        logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "        bucket=bckt_nm\n",
    "        photos=pics\n",
    "        model=modelarn\n",
    "        min_confidence=minconfdnce\n",
    "       \n",
    "\n",
    "        rek_client=boto3.client('rekognition')\n",
    "        \n",
    "        s3_connection = boto3.resource('s3')\n",
    "        for photo in photos:\n",
    "            label_count=analyze_s3_image(rek_client,\n",
    "                s3_connection,\n",
    "                model,\n",
    "                bucket,\n",
    "                photo,\n",
    "                min_confidence)\n",
    "\n",
    "        \"\"\"\n",
    "        # Uncomment to analyze a local file. \n",
    "        # Change photo to the path and file name of a local file.\n",
    "        label_count=analyze_local_image(rek_client,\n",
    "            model,\n",
    "            photo,\n",
    "            min_confidence)\n",
    "        \n",
    "        \"\"\" \n",
    "        logger.info(f\"Custom labels detected: {label_count}\")\n",
    "\n",
    "    except ClientError as err:\n",
    "        print(\"A service client error occurred: \" + format(err.response[\"Error\"][\"Message\"]))\n",
    "    except ValueError as err:\n",
    "        print (\"A value error occurred: \" + format(err))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cae792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Test the model on the holdout dataset\n",
    "bucket_nm=rek_cl_default_bucket\n",
    "holdout_photos=[('stanford_dog_dataset/holdout/' + f) for f in listdir('./stanford_dog_dataset/holdout') if (isfile(join('./stanford_dog_dataset/holdout', f)) and ((f.split(\".\")[-1]) == 'jpg' ) )]\n",
    "model_arn=model_metrics['ProjectVersionDescriptions'][0]['ProjectVersionArn']\n",
    "min_confidence=70\n",
    "\n",
    "analyze_rekcl_bb(bucket_nm, holdout_photos, model_arn, min_confidence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de07ddd1",
   "metadata": {},
   "source": [
    "### Stop the trained model\n",
    "***\n",
    "Here we will use the [stop_project_version](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.stop_project_version) API to retrive the trained model metrics.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_model = rekognition.stop_project_version(\n",
    "                        ProjectVersionArn=model_metrics['ProjectVersionDescriptions'][0]['ProjectVersionArn']\n",
    "                    )\n",
    "JSON (stop_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wait for the model to stop\n",
    "chk_status = True\n",
    "starttime = time.time()\n",
    "while (chk_status):\n",
    "    ## wait for 1 minute. To check status every 1 minutes\n",
    "    time.sleep (60)\n",
    "    model_stop_status = rekognition.describe_project_versions(\n",
    "                                ProjectArn=cl_project['ProjectArn'],\n",
    "                                VersionNames=[\n",
    "                                               model_version_name\n",
    "                                            ]\n",
    "        \n",
    "                            )\n",
    "    if ( (model_stop_status['ProjectVersionDescriptions'][0]['Status'] != 'STOPPING') ):\n",
    "        chk_status = False\n",
    "    ## Continue to check for status for 1 hour\n",
    "    if ((time.time() - starttime) > 3600):\n",
    "        chk_status = False\n",
    "        # Raise an exception if needed\n",
    "        \n",
    "JSON(model_stop_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0f071",
   "metadata": {},
   "source": [
    "You have successfully used Amazon Rekognition Custom Label APIs to run a end to end Rekognition Custom Label Training and Inference flows to detect dog breeds.\n",
    "<br>You must have noticed that the image Saluki.jpg (this is an image of a dog which breed was not included in the training dataset) is incorrectly classified most probably as golden retriever becasue they look similar.\n",
    "<br>For the model to detect Saluki dog breed, we will continue with this project to add Saluki dog breed images to the datasets and retrigger training. By providing more images related to Saluki dog breed would help the model differentiate between a Saluki and Golden retriver dog breed. Refer the notebook [Add images to the datasets and retrigger a training job using Rekognition Custom Label APIs](add-images-to-datasets-and-retrigger-training-job-using-rekognition-custom-labels-api.ipynb) notebook in the same directory\n",
    "<br>The apis can be leveraged to integrate with your current system or your existing ML/AI flows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b2a4f0",
   "metadata": {},
   "source": [
    "### Learn more about different Rekognition Custom Labels APIs\n",
    "***\n",
    "To learn more about the Rekognition Custom Labels APIs [Amazon Rekognition Custom Labels API reference](https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/custom-labels-api-reference.html)\n",
    "\n",
    "Also refer the [Add images to the datasets and retrigger a training job using Rekognition Custom Label APIs](add-images-to-datasets-and-retrigger-training-job-using-rekognition-custom-labels-api.ipynb) notebook in the same directory.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd980d3",
   "metadata": {},
   "source": [
    "Stop the Amazon Sagemaker Notebook instance, if you created one to run the demonstration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
